package impl

import (
	"context"
	"fmt"
	"log"
	"path/filepath"

	"github.com/aether/sync/internal/domain/entity"
	"github.com/aether/sync/internal/domain/repository"
	"github.com/aether/sync/internal/domain/usecase"
	"github.com/aether/sync/pkg/chunking"
)

// ChunkingUseCaseImpl ChunkingUseCase'in concrete implementation'Ä±
// Single Responsibility: Chunking orchestration
// Dependency Inversion: Interface'lere baÄŸÄ±mlÄ±, concrete types'a deÄŸil
type ChunkingUseCaseImpl struct {
	chunkRepo  repository.ChunkRepository
	fileRepo   repository.FileRepository
	chunker    chunking.Chunker
	storage    chunking.ChunkStorage
	verifier   chunking.ChunkVerifier
}

// NewChunkingUseCase yeni bir ChunkingUseCaseImpl oluÅŸturur (Factory)
func NewChunkingUseCase(
	chunkRepo repository.ChunkRepository,
	fileRepo repository.FileRepository,
	chunker chunking.Chunker,
	storage chunking.ChunkStorage,
	verifier chunking.ChunkVerifier,
) usecase.ChunkingUseCase {
	return &ChunkingUseCaseImpl{
		chunkRepo: chunkRepo,
		fileRepo:  fileRepo,
		chunker:   chunker,
		storage:   storage,
		verifier:  verifier,
	}
}

// ChunkAndStoreFile dosyayÄ± chunk'lara bÃ¶ler, disk'e yazar ve DB'ye kaydeder
// Single Responsibility: Orchestrate chunking process
func (uc *ChunkingUseCaseImpl) ChunkAndStoreFile(
	ctx context.Context,
	fileID, filePath string,
) ([]*entity.Chunk, string, error) {
	log.Printf("ğŸ“¦ Chunking baÅŸlatÄ±lÄ±yor: %s", filepath.Base(filePath))

	// 1. DosyayÄ± chunk'lara bÃ¶l
	chunkResults, err := uc.chunker.ChunkFile(filePath)
	if err != nil {
		return nil, "", fmt.Errorf("dosya chunk'lanamadÄ±: %w", err)
	}

	log.Printf("   âœ“ %d chunk oluÅŸturuldu", len(chunkResults))

	// 2. Global hash hesapla
	globalHash := chunking.CalculateFileHash(chunkResults)

	// 3. Chunk'larÄ± iÅŸle (DB + Storage)
	chunks := make([]*entity.Chunk, 0, len(chunkResults))

	for i, cr := range chunkResults {
		// Chunk entity oluÅŸtur
		chunk := entity.NewChunk(cr.Hash, cr.Size)

		// DB'ye kaydet (deduplication otomatik)
		if err := uc.chunkRepo.Create(ctx, chunk); err != nil {
			return nil, "", fmt.Errorf("chunk DB'ye kaydedilemedi [%d]: %w", i, err)
		}

		// Disk'e kaydet (zaten varsa skip edilir)
		if err := uc.storage.Store(cr.Hash, cr.Data); err != nil {
			return nil, "", fmt.Errorf("chunk disk'e yazÄ±lamadÄ± [%d]: %w", i, err)
		}

		// File-Chunk iliÅŸkisi oluÅŸtur
		fileChunk := entity.NewFileChunk(fileID, cr.Hash, cr.Index)
		if err := uc.chunkRepo.CreateFileChunk(ctx, fileChunk); err != nil {
			return nil, "", fmt.Errorf("file-chunk iliÅŸkisi oluÅŸturulamadÄ± [%d]: %w", i, err)
		}

		chunks = append(chunks, chunk)
	}

	log.Printf("   âœ“ %d chunk kaydedildi (global_hash: %s...)", len(chunks), globalHash[:16])

	return chunks, globalHash, nil
}

// LoadFileChunks bir dosyanÄ±n chunk'larÄ±nÄ± yÃ¼kler
func (uc *ChunkingUseCaseImpl) LoadFileChunks(ctx context.Context, fileID string) ([]*entity.Chunk, error) {
	// File-chunks iliÅŸkisinden chunk'larÄ± getir
	chunks, err := uc.chunkRepo.GetChunksByFileID(ctx, fileID)
	if err != nil {
		return nil, fmt.Errorf("chunk'lar yÃ¼klenemedi: %w", err)
	}

	return chunks, nil
}

// VerifyFileIntegrity dosyanÄ±n bÃ¼tÃ¼nlÃ¼ÄŸÃ¼nÃ¼ doÄŸrular
// TÃ¼m chunk'larÄ±n hash'lerini kontrol eder ve global hash'i doÄŸrular
func (uc *ChunkingUseCaseImpl) VerifyFileIntegrity(
	ctx context.Context,
	fileID string,
	expectedGlobalHash string,
) error {
	// Chunk'larÄ± yÃ¼kle
	chunks, err := uc.LoadFileChunks(ctx, fileID)
	if err != nil {
		return fmt.Errorf("chunk'lar yÃ¼klenemedi: %w", err)
	}

	if len(chunks) == 0 {
		return fmt.Errorf("dosyanÄ±n chunk'larÄ± yok")
	}

	// Her chunk'Ä± doÄŸrula
	chunkResults := make([]*chunking.ChunkResult, 0, len(chunks))

	for i, chunk := range chunks {
		// Chunk verisini disk'ten oku
		data, err := uc.storage.Load(chunk.Hash)
		if err != nil {
			return fmt.Errorf("chunk [%d] yÃ¼klenemedi: %w", i, err)
		}

		// ChunkResult oluÅŸtur (verification iÃ§in)
		cr := &chunking.ChunkResult{
			Hash:   chunk.Hash,
			Index:  i,
			Size:   chunk.Size,
			Offset: int64(i) * entity.DefaultChunkSize,
			Data:   data,
		}

		// Chunk'Ä± doÄŸrula
		if err := uc.verifier.VerifyChunk(cr); err != nil {
			return fmt.Errorf("chunk [%d] doÄŸrulanamadÄ±: %w", i, err)
		}

		chunkResults = append(chunkResults, cr)
	}

	// Global hash doÄŸrula
	if err := chunking.VerifyFile(chunkResults, expectedGlobalHash); err != nil {
		return fmt.Errorf("dosya bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ doÄŸrulanamadÄ±: %w", err)
	}

	return nil
}

// DeleteFileChunks bir dosyanÄ±n chunk'larÄ±nÄ± siler (DB + disk)
// Deduplication aware: Sadece bu dosyada kullanÄ±lan chunk'larÄ± siler
func (uc *ChunkingUseCaseImpl) DeleteFileChunks(ctx context.Context, fileID string) error {
	// DosyanÄ±n chunk'larÄ±nÄ± getir
	fileChunks, err := uc.chunkRepo.GetFileChunks(ctx, fileID)
	if err != nil {
		return fmt.Errorf("chunk'lar alÄ±namadÄ±: %w", err)
	}

	// Her chunk iÃ§in referans kontrolÃ¼ yap
	for _, fc := range fileChunks {
		// KaÃ§ dosyada kullanÄ±lÄ±yor?
		refCount, err := uc.chunkRepo.CountChunkReferences(ctx, fc.ChunkHash)
		if err != nil {
			log.Printf("   âš ï¸ Chunk referans sayÄ±mÄ± baÅŸarÄ±sÄ±z: %s", fc.ChunkHash)
			continue
		}

		// Sadece bu dosyada kullanÄ±lÄ±yorsa sil
		if refCount <= 1 {
			// Disk'ten sil
			if err := uc.storage.Delete(fc.ChunkHash); err != nil {
				log.Printf("   âš ï¸ Chunk disk'ten silinemedi: %s - %v", fc.ChunkHash, err)
			}

			// DB'den sil
			if err := uc.chunkRepo.Delete(ctx, fc.ChunkHash); err != nil {
				log.Printf("   âš ï¸ Chunk DB'den silinemedi: %s - %v", fc.ChunkHash, err)
			}
		}
	}

	// File-chunk iliÅŸkilerini sil
	if err := uc.chunkRepo.DeleteFileChunks(ctx, fileID); err != nil {
		return fmt.Errorf("file-chunk iliÅŸkileri silinemedi: %w", err)
	}

	log.Printf("   âœ“ Dosya chunk'larÄ± temizlendi: %s", fileID)

	return nil
}

// GetChunkData chunk verisini disk'ten okur
func (uc *ChunkingUseCaseImpl) GetChunkData(ctx context.Context, hash string) ([]byte, error) {
	// Chunk DB'de var mÄ± kontrol et
	chunk, err := uc.chunkRepo.GetByHash(ctx, hash)
	if err != nil {
		return nil, fmt.Errorf("chunk bulunamadÄ±: %w", err)
	}

	// Local deÄŸilse hata
	if !chunk.IsLocal {
		return nil, fmt.Errorf("chunk bu cihazda yok (remote)")
	}

	// Disk'ten oku
	data, err := uc.storage.Load(hash)
	if err != nil {
		return nil, fmt.Errorf("chunk yÃ¼klenemedi: %w", err)
	}

	// BÃ¼tÃ¼nlÃ¼k kontrolÃ¼
	if err := uc.verifier.Verify(data, hash); err != nil {
		return nil, fmt.Errorf("chunk bÃ¼tÃ¼nlÃ¼k hatasÄ±: %w", err)
	}

	return data, nil
}

// GetDeduplicationStats deduplication istatistiklerini dÃ¶ndÃ¼rÃ¼r
func (uc *ChunkingUseCaseImpl) GetDeduplicationStats(
	ctx context.Context,
) (totalChunks, uniqueChunks int64, savingsBytes int64, err error) {
	// TÃ¼m local chunk'larÄ± getir
	chunks, err := uc.chunkRepo.GetLocalChunks(ctx)
	if err != nil {
		return 0, 0, 0, fmt.Errorf("chunk'lar alÄ±namadÄ±: %w", err)
	}

	uniqueChunks = int64(len(chunks))

	// Her chunk iÃ§in referans sayÄ±sÄ±nÄ± topla
	totalRefs := int64(0)
	totalSize := int64(0)

	for _, chunk := range chunks {
		refCount, err := uc.chunkRepo.CountChunkReferences(ctx, chunk.Hash)
		if err != nil {
			continue
		}

		totalRefs += int64(refCount)
		totalSize += chunk.Size

		// Savings hesapla (deduplication ile kazanÄ±lan alan)
		if refCount > 1 {
			savingsBytes += chunk.Size * int64(refCount-1)
		}
	}

	totalChunks = totalRefs

	return totalChunks, uniqueChunks, savingsBytes, nil
}
